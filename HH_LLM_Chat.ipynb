{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-13T12:48:56.389391Z",
          "iopub.status.busy": "2025-06-13T12:48:56.388862Z",
          "iopub.status.idle": "2025-06-13T12:49:01.380392Z",
          "shell.execute_reply": "2025-06-13T12:49:01.379427Z",
          "shell.execute_reply.started": "2025-06-13T12:48:56.389349Z"
        },
        "id": "Ugw7an72CVBE",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import gradio as gr\n",
        "import re\n",
        "from sentence_transformers import CrossEncoder\n",
        "from collections import Counter\n",
        "from bs4 import BeautifulSoup\n",
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMxUWFBzWGIY"
      },
      "source": [
        "# Модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-06-13T12:49:01.381155Z",
          "iopub.status.idle": "2025-06-13T12:49:01.381406Z",
          "shell.execute_reply": "2025-06-13T12:49:01.381287Z",
          "shell.execute_reply.started": "2025-06-13T12:49:01.381278Z"
        },
        "id": "eoO-YuEQVpQe",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "GOOGLE_API_KEY = os.getenv('GOOGLE_API')\n",
        "if not GOOGLE_API_KEY:\n",
        "    raise ValueError(\"GOOGLE_API_KEY не установлен. Пожалуйста, установите его как переменную окружения.\")\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "# === 1. Выбор модели Gemini ===\n",
        "# Gemini 1.5 Flash - это \"gemini-1.5-flash-latest\" или \"gemini-1.5-flash\"\n",
        "GEMINI_MODEL_NAME = \"gemini-1.5-flash-latest\"\n",
        "\n",
        "# Инициализация модели Gemini\n",
        "# safety_settings по умолчанию довольно строгие, можно ослабить, если нужно\n",
        "generation_config = {\n",
        "    \"temperature\": 0.3, # Контроль \"креативности\", 0.3 - довольно конкретный\n",
        "    \"top_p\": 0.95,      # Контроль разнообразия\n",
        "    \"max_output_tokens\": 2000, # Максимальное количество токенов в ответе Gemini\n",
        "}\n",
        "\n",
        "# Инициализация модели, передавая конфигурацию генерации\n",
        "# Это позволит не передавать параметры каждый раз при вызове generate_content\n",
        "gemini_model = genai.GenerativeModel(\n",
        "    model_name=GEMINI_MODEL_NAME,\n",
        "    generation_config=generation_config\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XZ5HRqeflVtL"
      },
      "outputs": [],
      "source": [
        "def ask_gemini_model(question, context=\"\"):\n",
        "    context = \"\\n---\\n\".join([desc for desc in df['description']])\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"parts\": [\n",
        "            \"Ты — полезный AI-помощник, который анализирует информацию из описаний вакансий.\\n\"\n",
        "            \"Отвечай на вопросы, основываясь СТРОГО на предоставленном КОНТЕКСТЕ.\\n\"\n",
        "        ]},\n",
        "        {\"role\": \"model\", \"parts\": [\"Понял. Я готов отвечать на вопросы строго по предоставленному контексту о вакансиях.\"]},\n",
        "        {\"role\": \"user\", \"parts\": [\n",
        "            f\"КОНТЕКСТ:\\n{context}\\n\\nВОПРОС: {question}\"\n",
        "        ]}\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        # Вызов API Gemini\n",
        "        response = gemini_model.generate_content(messages)\n",
        "        return response.text.strip()\n",
        "    except Exception as e:\n",
        "        # Если модель не смогла сгенерировать ответ (например, из-за safety settings или ошибки API)\n",
        "        print(f\"Ошибка при запросе к Gemini API: {e}\")\n",
        "        # Если response.prompt_feedback содержит block_reason, это из-за Safety Settings\n",
        "        if hasattr(response, 'prompt_feedback') and response.prompt_feedback.block_reason:\n",
        "            return f\"Ответ заблокирован из-за настроек безопасности: {response.prompt_feedback.block_reason}\"\n",
        "        return f\"Неизвестная ошибка: {e}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnvFL01DWI2D"
      },
      "source": [
        "# Отображение"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESTHuU9OlI3Q"
      },
      "source": [
        "## Зарплаты"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-13T12:48:25.591336Z",
          "iopub.status.busy": "2025-06-13T12:48:25.591083Z",
          "iopub.status.idle": "2025-06-13T12:48:25.600948Z",
          "shell.execute_reply": "2025-06-13T12:48:25.600426Z",
          "shell.execute_reply.started": "2025-06-13T12:48:25.591315Z"
        },
        "id": "neO5xSYZVpQe",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def clean_salary_value(salary_str):\n",
        "    cleaned = re.sub(r'[^\\d]', '', salary_str)\n",
        "\n",
        "    try:\n",
        "        if cleaned: # Проверяем, что строка не пуста после очистки\n",
        "            return int(cleaned)\n",
        "        else:\n",
        "            return None\n",
        "    except ValueError:\n",
        "        return None\n",
        "\n",
        "def plot_salaries():\n",
        "    global df # Убедимся, что работаем с глобальным df\n",
        "\n",
        "    if 'df' not in globals() or df.empty:\n",
        "        print(\"DEBUG: DataFrame пуст или не инициализирован в plot_salaries.\")\n",
        "        fig = px.bar(title=\"График зарплат (Загрузите вакансии)\")\n",
        "        fig.update_layout(xaxis_title=\"Вакансия\", yaxis_title=\"Зарплата\")\n",
        "        return fig\n",
        "\n",
        "\n",
        "    salaries_processed = []\n",
        "    for salary_entry in df['salary']:\n",
        "        from_val = None\n",
        "        to_val = None\n",
        "        if isinstance(salary_entry, str):\n",
        "            if 'от' in salary_entry:\n",
        "                parts = salary_entry.split('от')\n",
        "                if len(parts) > 1:\n",
        "                    from_val = clean_salary_value(parts[1])\n",
        "            elif 'до' in salary_entry:\n",
        "                parts = salary_entry.split('до')\n",
        "                if len(parts) > 1:\n",
        "                    to_val = clean_salary_value(parts[1])\n",
        "            else:\n",
        "                # Попробуем извлечь первое число, если нет \"от\" или \"до\"\n",
        "                numbers = re.findall(r'\\d+', salary_entry)\n",
        "                if numbers:\n",
        "                    from_val = clean_salary_value(numbers[0])\n",
        "                    if len(numbers) > 1: # Если есть диапазон, возьмем второе число как \"до\"\n",
        "                        to_val = clean_salary_value(numbers[1])\n",
        "\n",
        "        salaries_processed.append({'salary_from_val': from_val, 'salary_to_val': to_val})\n",
        "\n",
        "    salary_df_processed = pd.DataFrame(salaries_processed)\n",
        "\n",
        "    plot_df = pd.DataFrame()\n",
        "    plot_df['Вакансия'] = df['name']\n",
        "    plot_df['Зарплата (начало)'] = salary_df_processed['salary_from_val']\n",
        "    plot_df['Зарплата (конец)'] = salary_df_processed['salary_to_val']\n",
        "\n",
        "    # Если 'salary_from_val' пуст, но есть 'salary_to_val', используем 'salary_to_val' как 'начало'\n",
        "    plot_df['Зарплата (начало)'] = plot_df['Зарплата (начало)'].fillna(plot_df['Зарплата (конец)'])\n",
        "    # Если 'salary_to_val' пуст, но есть 'salary_from_val', используем 'salary_from_val' как 'конец'\n",
        "    plot_df['Зарплата (конец)'] = plot_df['Зарплата (конец)'].fillna(plot_df['Зарплата (начало)'])\n",
        "\n",
        "    plot_df = plot_df[plot_df['Зарплата (начало)'] < 5000000]\n",
        "\n",
        "    if plot_df.empty:\n",
        "        print(\"DEBUG: plot_df пуст после обработки зарплат.\")\n",
        "        fig = px.bar(title=\"График зарплат (Нет данных о зарплате)\",\n",
        "                     labels={'Вакансия': 'Вакансия', 'Зарплата': 'Зарплата'})\n",
        "        return fig\n",
        "\n",
        "    # Создаем график\n",
        "    fig = px.box(plot_df,\n",
        "                 y='Зарплата (начало)', # Используем \"начало\" для высоты столбца\n",
        "                 hover_data={'Зарплата (конец)': True, 'Вакансия': False}, # Показываем \"до\" при наведении\n",
        "                 title='Зарплаты по вакансиям',\n",
        "                 height=300,\n",
        "                 labels={'Зарплата (начало)': 'Зарплата'})\n",
        "    fig.update_layout(xaxis_title=\"Box plot\", yaxis_title=\"Зарплата\")\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLHgFmmrWKCC"
      },
      "source": [
        "## Уровни вакансий"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-13T12:48:36.327834Z",
          "iopub.status.busy": "2025-06-13T12:48:36.327582Z",
          "iopub.status.idle": "2025-06-13T12:48:36.337934Z",
          "shell.execute_reply": "2025-06-13T12:48:36.337214Z",
          "shell.execute_reply.started": "2025-06-13T12:48:36.327815Z"
        },
        "id": "VCEBGMYiVpQf",
        "jupyter": {
          "source_hidden": true
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def analyze_levels():\n",
        "    global df # Убедимся, что мы работаем с глобальным df\n",
        "\n",
        "    if 'df' not in globals() or df.empty:\n",
        "        fig = px.pie(title=\"Распределение уровней (Загрузите вакансии)\")\n",
        "        fig.update_layout(\n",
        "            annotations=[\n",
        "                dict(\n",
        "                    text=\"Данные об уровнях отсутствуют или не загружены.\",\n",
        "                    xref=\"paper\", yref=\"paper\",\n",
        "                    showarrow=False,\n",
        "                    font=dict(size=14, color=\"gray\")\n",
        "                )\n",
        "            ]\n",
        "        )\n",
        "        return fig\n",
        "\n",
        "    # Убедимся, что столбец 'name' существует\n",
        "    if 'name' not in df.columns:\n",
        "        fig = px.pie(title=\"Распределение уровней (Отсутствует столбец 'name')\")\n",
        "        fig.update_layout(\n",
        "            annotations=[\n",
        "                dict(\n",
        "                    text=\"Для анализа уровней требуется столбец 'name'.\",\n",
        "                    xref=\"paper\", yref=\"paper\",\n",
        "                    showarrow=False,\n",
        "                    font=dict(size=14, color=\"gray\")\n",
        "                )\n",
        "            ]\n",
        "        )\n",
        "        return fig\n",
        "\n",
        "    levels_data = []\n",
        "    # Паттерн для поиска уровней в названии вакансии (регистронезависимый)\n",
        "    # Добавлены границы слов \\b для более точного соответствия\n",
        "    level_pattern = re.compile(r'\\b(junior|middle|senior|lead|staff)\\b', re.IGNORECASE)\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        vacancy_name = row['name']\n",
        "        level = 'Неизвестно' # Значение по умолчанию\n",
        "\n",
        "        if isinstance(vacancy_name, str):\n",
        "            match = level_pattern.search(vacancy_name)\n",
        "            if match:\n",
        "                detected_level = match.group(0).capitalize()\n",
        "                # Убедимся, что это одно из ожидаемых слов-уровней\n",
        "                if detected_level in ['Junior', 'Middle', 'Senior', 'Lead', 'Staff']:\n",
        "                    level = detected_level\n",
        "        levels_data.append({'Вакансия': vacancy_name, 'Уровень': level})\n",
        "\n",
        "    if not levels_data:\n",
        "        fig = px.pie(title=\"Распределение уровней (Не удалось определить уровни)\")\n",
        "        fig.update_layout(\n",
        "            annotations=[\n",
        "                dict(\n",
        "                    text=\"Не удалось определить уровни для загруженных вакансий.\",\n",
        "                    xref=\"paper\", yref=\"paper\",\n",
        "                    showarrow=False,\n",
        "                    font=dict(size=14, color=\"gray\")\n",
        "                )\n",
        "            ]\n",
        "        )\n",
        "        return fig\n",
        "\n",
        "    levels_df = pd.DataFrame(levels_data)\n",
        "\n",
        "    # Подсчет количества вакансий для каждого уровня\n",
        "    level_counts = levels_df['Уровень'].value_counts().reset_index()\n",
        "    level_counts.columns = ['Уровень', 'Количество']\n",
        "\n",
        "\n",
        "    # Определяем желаемый порядок отображения уровней на графике\n",
        "    level_order = ['Junior', 'Middle', 'Senior', 'Lead', 'Staff', 'Неизвестно']\n",
        "\n",
        "    # Преобразуем столбец 'Уровень' в категориальный тип с заданным порядком\n",
        "    # Esto asegura que las categorías ausentes no causen errores\n",
        "    level_counts['Уровень'] = pd.Categorical(level_counts['Уровень'], categories=level_order, ordered=True)\n",
        "\n",
        "    # Сортируем DataFrame по новому категориальному столбцу для правильного отображения\n",
        "    level_counts = level_counts.sort_values(by='Уровень')\n",
        "\n",
        "\n",
        "    if level_counts.empty:\n",
        "        fig = px.pie(title=\"Распределение уровней (Нет данных для построения)\")\n",
        "        fig.update_layout(\n",
        "            annotations=[\n",
        "                dict(\n",
        "                    text=\"Недостаточно данных для построения круговой диаграммы уровней.\",\n",
        "                    xref=\"paper\", yref=\"paper\",\n",
        "                    showarrow=False,\n",
        "                    font=dict(size=14, color=\"gray\")\n",
        "                )\n",
        "            ]\n",
        "        )\n",
        "        return fig\n",
        "\n",
        "\n",
        "    # Создаем круговую диаграмму с помощью Plotly Express\n",
        "    fig = px.pie(level_counts,\n",
        "                 values='Количество',\n",
        "                 names='Уровень',\n",
        "                 title='Распределение уровней вакансий по названию',\n",
        "                 labels={'Уровень': 'Уровень кандидата', 'Количество': 'Количество вакансий'},\n",
        "                 color='Уровень', # Раскрашиваем секторы по уровням\n",
        "                 height=300)\n",
        "\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-lAoeWHWMCc"
      },
      "source": [
        "## Ключевые навыки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-13T12:48:52.4191Z",
          "iopub.status.busy": "2025-06-13T12:48:52.418648Z",
          "iopub.status.idle": "2025-06-13T12:48:52.425203Z",
          "shell.execute_reply": "2025-06-13T12:48:52.424523Z",
          "shell.execute_reply.started": "2025-06-13T12:48:52.419077Z"
        },
        "id": "QGiog9zkVpQf",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def show_skills():\n",
        "    if 'df' not in globals() or df.empty:\n",
        "        # Return a placeholder plot if no data\n",
        "        fig = px.bar(title=\"Гистограмма навыков (Загрузите вакансии)\",\n",
        "                     labels={'x': 'Навык', 'y': 'Частота'})\n",
        "        return fig\n",
        "\n",
        "    all_skills = []\n",
        "    for skills_list in df['key_skills']:\n",
        "        if isinstance(skills_list, list):\n",
        "            for skill_dict in skills_list:\n",
        "                if isinstance(skill_dict, dict) and 'name' in skill_dict and len(skill_dict['name']) < 40:\n",
        "                    all_skills.append(skill_dict['name'])\n",
        "\n",
        "    if not all_skills:\n",
        "        fig = px.bar(title=\"Гистограмма навыков (Навыки не найдены)\",\n",
        "                     labels={'x': 'Навык', 'y': 'Частота'})\n",
        "        return fig\n",
        "\n",
        "    skill_counts = Counter(all_skills)\n",
        "    skill_df = pd.DataFrame(skill_counts.items(), columns=['Навык', 'Частота'])\n",
        "    skill_df = skill_df.sort_values(by='Частота', ascending=False).head(20) # Top 20 skills\n",
        "\n",
        "    fig = px.bar(skill_df,\n",
        "                 x='Навык',\n",
        "                 y='Частота',\n",
        "                 title='Топ 20 наиболее частых ключевых навыков',\n",
        "                 labels={'Навык': 'Навык', 'Частота': 'Количество вакансий'},\n",
        "                 height=300)\n",
        "    fig.update_layout(xaxis={'categoryorder':'total descending'}) # Order bars by frequency\n",
        "\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KB08nhh8WNiT"
      },
      "source": [
        "# Пасинг вакансий"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-13T11:37:14.768344Z",
          "iopub.status.busy": "2025-06-13T11:37:14.767736Z",
          "iopub.status.idle": "2025-06-13T11:37:14.778802Z",
          "shell.execute_reply": "2025-06-13T11:37:14.77805Z",
          "shell.execute_reply.started": "2025-06-13T11:37:14.76832Z"
        },
        "id": "0IzWenbvvGmD",
        "jupyter": {
          "source_hidden": true
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "HH_API = \"https://api.hh.ru/vacancies\"\n",
        "\n",
        "def fetch_vacancies(query, count):\n",
        "    global df\n",
        "    # Инициализация всех возвращаемых значений на случай ошибки\n",
        "    status_message = \"Инициализация...\"\n",
        "    skills_output_val = \"Навыки не загружены.\"\n",
        "    salary_plot_output_val = plot_salaries() # Вызов для получения пустого графика-заглушки\n",
        "    levels_output_val = \"Уровни не загружены.\"\n",
        "\n",
        "    try:\n",
        "        params = {\n",
        "            \"text\": query,\n",
        "            \"order_by\": \"relevance\",\n",
        "            \"label\": \"with_salary\",\n",
        "            \"per_page\": count,\n",
        "            \"search_field\": [\"name\", \"description\"],\n",
        "        }\n",
        "        response = requests.get(HH_API, params=params)\n",
        "        response.raise_for_status() # Вызывает HTTPError для статусов 4xx/5xx\n",
        "\n",
        "        items = response.json().get(\"items\", [])\n",
        "        vacancies = []\n",
        "\n",
        "        for item in items:\n",
        "            try:\n",
        "                vacancy_url = item['url']\n",
        "                details = requests.get(vacancy_url).json()\n",
        "\n",
        "                description = details.get('description', '')\n",
        "                if description:\n",
        "                    soup = BeautifulSoup(description, 'html.parser')\n",
        "                    description = soup.get_text(separator=' ').strip()\n",
        "\n",
        "                salary = item.get(\"salary\")\n",
        "\n",
        "                key_skills = details['key_skills']\n",
        "\n",
        "                if salary:\n",
        "                    salary_str = f\"{salary.get('from', '')} - {salary.get('to', '')} {salary.get('currency', '')}\"\n",
        "\n",
        "                vacancies.append({\n",
        "                    \"name\": item.get(\"name\"),\n",
        "                    \"employer\": item.get(\"employer\", {}).get(\"name\"),\n",
        "                    \"description\": description,\n",
        "                    \"key_skills\": key_skills,\n",
        "                    \"salary\": salary_str,\n",
        "                    \"url\": item.get(\"alternate_url\")\n",
        "                })\n",
        "            except Exception as e:\n",
        "                print(f\"Ошибка при обработке отдельной вакансии '{item.get('name', 'N/A')}': {e}\")\n",
        "                continue # Продолжаем обработку других вакансий\n",
        "\n",
        "        df = pd.DataFrame(vacancies)\n",
        "\n",
        "        if not df.empty:\n",
        "            status_message = f'Загружено {len(df)} вакансий успешно!'\n",
        "            # Если данные загружены, вычисляем реальные значения\n",
        "            skills_output_val = show_skills()\n",
        "            salary_plot_output_val = plot_salaries()\n",
        "            levels_output_val = analyze_levels()\n",
        "            reqs_output = ask_gemini_model('Составть требования, чтобы получить работу из контекста. Делай общую суммаризацию со всех вакансий')\n",
        "            strat_output = ask_gemini_model('Составть стратегию, чтобы получить работу из контекста')\n",
        "            resume_output = ask_gemini_model('Составть шаблон резюме, чтобы получить работу из контекста. Придумай идеального кандидата и напиши для него этот шаблон. Сделай его 1 универсальный насколько можешь')\n",
        "        else:\n",
        "            status_message = 'Вакансий не найдено по вашему запросу.'\n",
        "            # Если вакансий нет, можно оставить заглушки или установить более информативные сообщения\n",
        "            skills_output_val = \"Вакансий не найдено для анализа навыков.\"\n",
        "            salary_plot_output_val = plot_salaries() # Вернет пустой график с сообщением\n",
        "            levels_output_val = \"Вакансий не найдено для анализа уровней.\"\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        status_message = f\"Ошибка подключения к HH.ru или HTTP-ошибка: {e}\"\n",
        "        print(f\"Ошибка HTTP запроса: {e}\")\n",
        "        df = pd.DataFrame() # Обнуляем DataFrame на случай ошибки\n",
        "    except ValueError as e: # Для ошибок парсинга JSON\n",
        "        status_message = f\"Ошибка парсинга ответа от HH.ru: {e}\"\n",
        "        print(f\"Ошибка JSON парсинга: {e}\")\n",
        "        df = pd.DataFrame()\n",
        "    except Exception as e:\n",
        "        status_message = f\"Произошла непредвиденная ошибка: {e}\"\n",
        "        print(f\"Непредвиденная ошибка в fetch_vacancies: {e}\")\n",
        "        df = pd.DataFrame()\n",
        "\n",
        "    # Гарантируем, что всегда возвращаются 4 значения\n",
        "    return skills_output_val, salary_plot_output_val, levels_output_val, reqs_output, strat_output, resume_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-13T12:11:36.616053Z",
          "iopub.status.busy": "2025-06-13T12:11:36.615532Z",
          "iopub.status.idle": "2025-06-13T12:11:36.622445Z",
          "shell.execute_reply": "2025-06-13T12:11:36.621818Z",
          "shell.execute_reply.started": "2025-06-13T12:11:36.616029Z"
        },
        "id": "-q1ECPnYvPZs",
        "jupyter": {
          "source_hidden": true
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def ask_gemini_model(question, context=\"\"):\n",
        "    context = \"\\n---\\n\".join([desc for desc in df['description']])\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"parts\": [\n",
        "            \"Ты — полезный AI-помощник, который анализирует информацию из описаний вакансий.\\n\"\n",
        "            \"Отвечай на вопросы, основываясь СТРОГО на предоставленном КОНТЕКСТЕ.\\n\"\n",
        "        ]},\n",
        "        {\"role\": \"model\", \"parts\": [\"Понял. Я готов отвечать на вопросы строго по предоставленному контексту о вакансиях.\"]},\n",
        "        {\"role\": \"user\", \"parts\": [\n",
        "            f\"КОНТЕКСТ:\\n{context}\\n\\nВОПРОС: {question}\"\n",
        "        ]}\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        # Вызов API Gemini\n",
        "        response = gemini_model.generate_content(messages)\n",
        "        return response.text.strip()\n",
        "    except Exception as e:\n",
        "        # Если модель не смогла сгенерировать ответ (например, из-за safety settings или ошибки API)\n",
        "        print(f\"Ошибка при запросе к Gemini API: {e}\")\n",
        "        # Если response.prompt_feedback содержит block_reason, это из-за Safety Settings\n",
        "        if hasattr(response, 'prompt_feedback') and response.prompt_feedback.block_reason:\n",
        "            return f\"Ответ заблокирован из-за настроек безопасности: {response.prompt_feedback.block_reason}\"\n",
        "        return f\"Неизвестная ошибка: {e}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEoHO6nUd_OK"
      },
      "source": [
        "# Интерфейс"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        },
        "execution": {
          "execution_failed": "2025-06-13T12:47:03.835Z",
          "iopub.execute_input": "2025-06-13T12:46:29.052517Z",
          "iopub.status.busy": "2025-06-13T12:46:29.051736Z"
        },
        "id": "kaDfGJz1k3Bg",
        "outputId": "3e912d57-0391-49f3-df5f-fe00f8373fed",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Готово! Запускаем интерфейс...\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://ec0315afb0755942ae.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://ec0315afb0755942ae.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://ec0315afb0755942ae.gradio.live\n"
          ]
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# 🤖 Анализатор вакансий HH.ru\")\n",
        "\n",
        "    with gr.Row():\n",
        "        query_input = gr.Textbox(label=\"Поисковый запрос (например, 'ML разработчик')\", value=\"Python разработчик\")\n",
        "        count_input = gr.Number(label=\"Сколько вакансий загрузить\", value=20, step=1, minimum=1, maximum=100)\n",
        "        load_btn = gr.Button(\"🔍 Загрузить вакансии\")\n",
        "\n",
        "    # Здесь объявляем компоненты, которые будут отображаться в колонках\n",
        "    # и привязываем их к кнопке загрузки\n",
        "    # Важно: объявляем их внутри Row/Column для правильного размещения\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(): # Первая колонка для навыков\n",
        "            gr.Markdown(\"## 📊 Анализ ключевых навыков\")\n",
        "            skills_output = gr.Plot(label=\"Навыки после загрузки\")\n",
        "        with gr.Column(): # Вторая колонка для уровней (можно настроить scale по желанию)\n",
        "            gr.Markdown(\"## 📈 Уровни вакансий\")\n",
        "            levels_output = gr.Plot(label=\"Уровни вакансий\")\n",
        "        with gr.Column():\n",
        "            gr.Markdown(\"## 💰 Анализ зарплат\")\n",
        "            salary_plot_output = gr.Plot(label=\"График зарплат\")\n",
        "\n",
        "    with gr.Row():\n",
        "      with gr.Column(): # Вторая колонка для уровней (можно настроить scale по желанию)\n",
        "            gr.Markdown(\"## Требования работодателей\")\n",
        "            reqs_output = gr.Textbox(label=\"Требования\")\n",
        "      with gr.Column():\n",
        "            gr.Markdown(\"## Стратегия, как найти эту работу\")\n",
        "            strat_output = gr.Textbox(label=\"Стратегия\")\n",
        "\n",
        "    with gr.Row():\n",
        "      with gr.Column(): # Вторая колонка для уровней (можно настроить scale по желанию)\n",
        "            gr.Markdown(\"## Шаблон резюме\")\n",
        "            resume_output = gr.Textbox(label=\"Резюме\")\n",
        "\n",
        "    # Привязываем кнопку загрузки ко всем соответствующим выходам\n",
        "    # Здесь используются переменные, которые были объявлены в своих колонках\n",
        "    load_btn.click(\n",
        "        fn=fetch_vacancies,\n",
        "        inputs=[query_input, count_input],\n",
        "        outputs=[skills_output, salary_plot_output, levels_output, reqs_output, strat_output, resume_output]\n",
        "    )\n",
        "\n",
        "    gr.Markdown(\"## 💬 Вопросы к загруженным вакансиям\")\n",
        "    question_input = gr.Textbox(label=\"Задайте вопрос по всем загруженным вакансиям (например, 'Каковы общие требования к опыту работы?' или 'Суммируй все описания вакансий.')\")\n",
        "    question_btn = gr.Button(\"Получить ответ / Суммаризировать\")\n",
        "    answer_output = gr.Textbox(label=\"Ответ Gemini\")\n",
        "\n",
        "    question_btn.click(fn=ask_gemini_model, inputs=question_input, outputs=answer_output)\n",
        "\n",
        "print(\"Готово! Запускаем интерфейс...\")\n",
        "demo.launch(share=True, debug=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 31041,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
